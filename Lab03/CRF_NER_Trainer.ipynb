{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 03 - NLP - Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-crfsuite in /home/diptesh/anaconda3/lib/python3.8/site-packages (0.9.7)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.2 is available.\n",
      "You should consider upgrading via the '/home/diptesh/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install python-crfsuite\n",
    "from itertools import chain\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import sklearn\n",
    "import pycrfsuite\n",
    "from nltk.corpus.reader import ConllChunkCorpusReader\n",
    "from seqeval.metrics import accuracy_score\n",
    "from seqeval.metrics import classification_report\n",
    "from seqeval.metrics import f1_score\n",
    "from seqeval.scheme import IOB1\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Train/Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2394\n"
     ]
    }
   ],
   "source": [
    "mycorpus = ConllChunkCorpusReader(r\"Twitter-NER/\", r\".*\\.train\",chunk_types=\"pos\")\n",
    "train_corpus = []\n",
    "for tree in mycorpus.tagged_sents():\n",
    "    train_corpus.append(tree)\n",
    "    \n",
    "print(len(train_corpus))\n",
    "# print(train_corpus[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3850\n"
     ]
    }
   ],
   "source": [
    "mycorpus = ConllChunkCorpusReader(r\"Twitter-NER/\", r\".*\\.test\",chunk_types=\"pos\")\n",
    "test_corpus = []\n",
    "for tree in mycorpus.tagged_sents():\n",
    "    test_corpus.append(tree)\n",
    "print(len(test_corpus))\n",
    "# print(test_corpus[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features\n",
    "Next, define some features. In this example we use word identity, word suffix, word shape; also, some information from nearby words is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Every word is represented by a set of features. CRF allows us to give any arbitrary set of features\n",
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    features = [\n",
    "        'bias',\n",
    "        'word.lower=' + word.lower(),\n",
    "        'word[-3:]=' + word[-3:],\n",
    "        'word[-2:]=' + word[-2:],\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "    ]\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "            '-1:word.isupper=%s' % word1.isupper(),\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "            '+1:word.istitle=%s' % word1.istitle(),\n",
    "            '+1:word.isupper=%s' % word1.isupper(),\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "                \n",
    "    return features\n",
    "\n",
    "def word2featuresTest(sent, i):\n",
    "    word = sent[i]\n",
    "    features = [\n",
    "        'bias',\n",
    "        'word.lower=' + word.lower(),\n",
    "        'word[-3:]=' + word[-3:],\n",
    "        'word[-2:]=' + word[-2:],\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "    ]\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "            '-1:word.isupper=%s' % word1.isupper(),\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "            '+1:word.istitle=%s' % word1.istitle(),\n",
    "            '+1:word.isupper=%s' % word1.isupper(),\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "                \n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2featuresTest(sent):\n",
    "    return [word2featuresTest(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('RT', 'O')\n",
      "['bias', 'word.lower=rt', 'word[-3:]=RT', 'word[-2:]=RT', 'word.isupper=True', 'word.istitle=False', 'word.isdigit=False', 'BOS', '+1:word.lower=@liltwist', '+1:word.istitle=False', '+1:word.isupper=False']\n"
     ]
    }
   ],
   "source": [
    "X_train = [sent2features(s) for s in train_corpus]\n",
    "y_train = [sent2labels(s) for s in train_corpus]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_corpus]\n",
    "y_test = [sent2labels(s) for s in test_corpus]\n",
    "\n",
    "print(train_corpus[5][0])\n",
    "print(X_train[5][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1%%time\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X_train, y_train):\n",
    "    trainer.append(xseq, yseq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer.set_params({\n",
    "    'c1': 1.0,   # coefficient for L1 penalty\n",
    "    'c2': 1e-4,  # coefficient for L2 penalty\n",
    "    'max_iterations': 100,  # stop earlier\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.83 s, sys: 37 Âµs, total: 6.83 s\n",
      "Wall time: 6.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train('twitter-ner.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x7f7583d75be0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('twitter-ner.crfsuite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 327 ms, sys: 0 ns, total: 327 ms\n",
      "Wall time: 326 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = [tagger.tag(xseq) for xseq in X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dumping Predictions to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open('crf.out.txt', 'w') as out_file:\n",
    "    for every_sent,pred_label in zip(test_corpus, y_pred):\n",
    "        for every_word_correct_label,predicted_label in zip(every_sent, pred_label):\n",
    "            out_file.write(every_word_correct_label[0] + \"\\t\" + every_word_correct_label[1] + \"\\t\" + predicted_label)\n",
    "            out_file.write(\"\\n\")\n",
    "        out_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conllReader(filename, word_field=0, label_field=1, prediction_field=2):\n",
    "    sentences_true_labels = []\n",
    "    sentences_pred_labels = []\n",
    "    true_list = []\n",
    "    pred_list = []\n",
    "    label_list = []\n",
    "    \n",
    "    with codecs.open(filename, 'r', errors='ignore', encoding='utf8') as f_in:\n",
    "        for line in f_in:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                if line.startswith('#'):\n",
    "                    continue\n",
    "                label = line.split('\\t')[label_field]\n",
    "                pred = line.split('\\t')[prediction_field]\n",
    "                true_list.append( label )\n",
    "                pred_list.append( pred )\n",
    "                \n",
    "            else:\n",
    "                if len(true_list) > 0:\n",
    "                    sentences_true_labels.append( true_list )\n",
    "                    sentences_pred_labels.append( pred_list )\n",
    "                true_list = []\n",
    "                pred_list = []\n",
    "        f_in.close()\n",
    "        \n",
    "    return sentences_true_labels, sentences_pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels, predicted_labels = conllReader(\"crf.out.txt\")\n",
    "# predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score is\n",
      "0.25871559633027524\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     company       0.72      0.10      0.18       586\n",
      "    facility       0.49      0.29      0.36       244\n",
      "     geo-loc       0.63      0.38      0.47       768\n",
      "       movie       0.33      0.04      0.06        28\n",
      " musicartist       0.11      0.01      0.01       180\n",
      "       other       0.23      0.07      0.10       535\n",
      "      person       0.33      0.22      0.26       466\n",
      "     product       0.33      0.02      0.04       216\n",
      "  sportsteam       0.00      0.00      0.00       128\n",
      "      tvshow       0.00      0.00      0.00        24\n",
      "\n",
      "   micro avg       0.48      0.18      0.26      3175\n",
      "   macro avg       0.32      0.11      0.15      3175\n",
      "weighted avg       0.44      0.18      0.23      3175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('F1 Score is')\n",
    "print( f1_score(true_labels, predicted_labels) )\n",
    "\n",
    "print('Classification report')\n",
    "print( classification_report(true_labels, predicted_labels, scheme=IOB1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attaching PoS Tagger-based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x7f7583d751c0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postagger = pycrfsuite.Tagger()\n",
    "postagger.open('twitter-ner.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Every word is represented by a set of features. CRF allows us to give any arbitrary set of features\n",
    "def word2featurespos(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][2]\n",
    "    features = [\n",
    "        'bias',\n",
    "        'word.lower=' + word.lower(),\n",
    "        'word[-3:]=' + word[-3:],\n",
    "        'word[-2:]=' + word[-2:],\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "        'postag=' + postag,\n",
    "        'postag[:2]=' + postag[:2],\n",
    "    ]\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][2]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "            '-1:word.isupper=%s' % word1.isupper(),\n",
    "            '-1:postag=' + postag1,\n",
    "            '-1:postag[:2]=' + postag1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][2]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "            '+1:word.istitle=%s' % word1.istitle(),\n",
    "            '+1:word.isupper=%s' % word1.isupper(),\n",
    "            '+1:postag=' + postag1,\n",
    "            '+1:postag[:2]=' + postag1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "                \n",
    "    return features\n",
    "\n",
    "def sent2featurespos(sent, postagger):\n",
    "    tagged = postagger.tag(sent2features(sent))\n",
    "    sentNew = [word_nelabel+(pos, ) for word_nelabel,pos in zip(sent, tagged)]\n",
    "    return [word2featurespos(sentNew, i) for i in range(len(sentNew))]\n",
    "\n",
    "def sent2labelspos(sent):\n",
    "    return [label for token, label in sent]\n",
    "\n",
    "def sent2tokenspos(sent):\n",
    "    return [token for token, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('@SammieLynnsMom', 'O'), ('@tg10781', 'O'), ('they', 'O'), ('will', 'O'), ('be', 'O'), ('all', 'O'), ('done', 'O'), ('by', 'O'), ('Sunday', 'O'), ('trust', 'O'), ('me', 'O'), ('*wink*', 'O')]\n",
      "\n",
      "\n",
      "[('@SammieLynnsMom', 'O', 'O'), ('@tg10781', 'O', 'O'), ('they', 'O', 'O'), ('will', 'O', 'O'), ('be', 'O', 'O'), ('all', 'O', 'O'), ('done', 'O', 'O'), ('by', 'O', 'O'), ('Sunday', 'O', 'O'), ('trust', 'O', 'O'), ('me', 'O', 'O'), ('*wink*', 'O', 'O')]\n"
     ]
    }
   ],
   "source": [
    "for sent in train_corpus:\n",
    "    print(sent)\n",
    "    print(\"\\n\")\n",
    "    s1 = postagger.tag(sent2features(sent))\n",
    "    sentNew = [word_nelabel+(pos, ) for word_nelabel,pos in zip(sent, s1)]\n",
    "    print(sentNew)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pos = [sent2featurespos(s, postagger) for s in train_corpus]\n",
    "y_train_pos = [sent2labelspos(s) for s in train_corpus]\n",
    "\n",
    "X_test_pos = [sent2featurespos(s, postagger) for s in test_corpus]\n",
    "y_test_pos = [sent2labelspos(s) for s in test_corpus]\n",
    "\n",
    "# print(X_train_pos[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainerpos = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X_train_pos, y_train_pos):\n",
    "    trainerpos.append(xseq, yseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainerpos.set_params({\n",
    "    'c1': 1.0,   # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 100,  # stop earlier\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.84 s, sys: 3.91 ms, total: 7.85 s\n",
      "Wall time: 7.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainerpos.train('twitter-ner-pos.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x7f758389f0d0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taggerpos = pycrfsuite.Tagger()\n",
    "taggerpos.open('twitter-ner-pos.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 490 ms, sys: 19 Âµs, total: 490 ms\n",
      "Wall time: 489 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred_pos = [taggerpos.tag(xseq) for xseq in X_test_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with codecs.open('crf.out.pos.txt', 'w') as out_file:\n",
    "    for every_sent,pred_label in zip(test_corpus, y_pred_pos):\n",
    "        for every_word_correct_label,predicted_label in zip(every_sent, pred_label):\n",
    "            out_file.write(every_word_correct_label[0] + \"\\t\" + every_word_correct_label[1] + \"\\t\" + predicted_label)\n",
    "            out_file.write(\"\\n\")\n",
    "        out_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels, predicted_labels = conllReader(\"crf.out.pos.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score is\n",
      "0.25929325378614043\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     company       0.72      0.10      0.18       586\n",
      "    facility       0.48      0.29      0.36       244\n",
      "     geo-loc       0.63      0.38      0.47       768\n",
      "       movie       0.33      0.04      0.06        28\n",
      " musicartist       0.11      0.01      0.01       180\n",
      "       other       0.23      0.07      0.10       535\n",
      "      person       0.33      0.22      0.27       466\n",
      "     product       0.33      0.02      0.04       216\n",
      "  sportsteam       0.00      0.00      0.00       128\n",
      "      tvshow       0.00      0.00      0.00        24\n",
      "\n",
      "   micro avg       0.48      0.18      0.26      3175\n",
      "   macro avg       0.32      0.11      0.15      3175\n",
      "weighted avg       0.44      0.18      0.24      3175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('F1 Score is')\n",
    "print( f1_score(true_labels, predicted_labels) )\n",
    "\n",
    "print('Classification report')\n",
    "print( classification_report(true_labels, predicted_labels, scheme=IOB1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Gazatteer features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus.reader import plaintext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "personGazetteer = []\n",
    "\n",
    "mycorpus = plaintext.PlaintextCorpusReader(\"./Twitter-NER/\", \"firstname.5000\")\n",
    "person = []\n",
    "for sent in mycorpus.words():\n",
    "    person.append(sent)\n",
    "    \n",
    "mycorpus = plaintext.PlaintextCorpusReader(\"./Twitter-NER/\", \"lastname.5000\")\n",
    "for sent in mycorpus.words():\n",
    "    person.append(sent)\n",
    "\n",
    "person = [name.lower() for name in person]\n",
    "personGazetteer = set(person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Every word is represented by a set of features. CRF allows us to give any arbitrary set of features\n",
    "def word2featuresGaz(sent, i, personGaz):\n",
    "    word = sent[i][0]\n",
    "    features = [\n",
    "        'bias',\n",
    "        'word.lower=' + word.lower(),\n",
    "        'word[-3:]=' + word[-3:],\n",
    "        'word[-2:]=' + word[-2:],\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "        'word.ispersongaz=%s' % (word.lower() in personGaz),\n",
    "    ]\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "            '-1:word.isupper=%s' % word1.isupper(),\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "            '+1:word.istitle=%s' % word1.istitle(),\n",
    "            '+1:word.isupper=%s' % word1.isupper(),\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "                \n",
    "    return features\n",
    "\n",
    "def word2featuresTest(sent, i):\n",
    "    word = sent[i]\n",
    "    features = [\n",
    "        'bias',\n",
    "        'word.lower=' + word.lower(),\n",
    "        'word[-3:]=' + word[-3:],\n",
    "        'word[-2:]=' + word[-2:],\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "    ]\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "            '-1:word.isupper=%s' % word1.isupper(),\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "            '+1:word.istitle=%s' % word1.istitle(),\n",
    "            '+1:word.isupper=%s' % word1.isupper(),\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "                \n",
    "    return features\n",
    "\n",
    "def sent2featuresGaz(sent, personGaz):\n",
    "    return [word2featuresGaz(sent, i, personGaz) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_gaz = [sent2featuresGaz(s, personGazetteer) for s in train_corpus]\n",
    "y_train_gaz = [sent2labels(s) for s in train_corpus]\n",
    "\n",
    "X_test_gaz = [sent2featuresGaz(s, personGazetteer) for s in test_corpus]\n",
    "y_test_gaz = [sent2labels(s) for s in test_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainergaz = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X_train_gaz, y_train_gaz):\n",
    "    trainergaz.append(xseq, yseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainergaz.set_params({\n",
    "    'c1': 1.0,   # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 150,  # stop earlier\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.7 s, sys: 3.27 ms, total: 9.7 s\n",
      "Wall time: 9.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainergaz.train('twitter-ner-gaz.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x7f758389fca0>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taggergaz = pycrfsuite.Tagger()\n",
    "taggergaz.open('twitter-ner-gaz.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 352 ms, sys: 0 ns, total: 352 ms\n",
      "Wall time: 352 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred_gaz = [taggergaz.tag(xseq) for xseq in X_test_gaz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with codecs.open('crf.out.gaz.txt', 'w') as out_file:\n",
    "    for every_sent,pred_label in zip(test_corpus, y_pred_gaz):\n",
    "        for every_word_correct_label,predicted_label in zip(every_sent, pred_label):\n",
    "            out_file.write(every_word_correct_label[0] + \"\\t\" + every_word_correct_label[1] + \"\\t\" + predicted_label)\n",
    "            out_file.write(\"\\n\")\n",
    "        out_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels, predicted_labels = conllReader(\"crf.out.gaz.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score is\n",
      "0.2762382718743181\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     company       0.75      0.10      0.18       586\n",
      "    facility       0.48      0.28      0.35       244\n",
      "     geo-loc       0.62      0.34      0.44       768\n",
      "       movie       0.14      0.04      0.06        28\n",
      " musicartist       0.12      0.01      0.01       180\n",
      "       other       0.27      0.08      0.12       535\n",
      "      person       0.34      0.41      0.38       466\n",
      "     product       0.29      0.02      0.04       216\n",
      "  sportsteam       0.00      0.00      0.00       128\n",
      "      tvshow       0.11      0.04      0.06        24\n",
      "\n",
      "   micro avg       0.45      0.20      0.28      3175\n",
      "   macro avg       0.31      0.13      0.16      3175\n",
      "weighted avg       0.45      0.20      0.25      3175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('F1 Score is')\n",
    "print( f1_score(true_labels, predicted_labels) )\n",
    "\n",
    "print('Classification report')\n",
    "print( classification_report(true_labels, predicted_labels, scheme=IOB1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding PoS Tag feature with the Gazetteer Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Every word is represented by a set of features. CRF allows us to give any arbitrary set of features\n",
    "def word2featuresposGaz(sent, i, personGaz):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][2]\n",
    "    features = [\n",
    "        'bias',\n",
    "        'word.lower=' + word.lower(),\n",
    "        'word[-3:]=' + word[-3:],\n",
    "        'word[-2:]=' + word[-2:],\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "        'postag=' + postag,\n",
    "        'postag[:2]=' + postag[:2],\n",
    "        'word.ispersongaz=%s' % (word.lower() in personGaz),\n",
    "    ]\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][2]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "            '-1:word.isupper=%s' % word1.isupper(),\n",
    "            '-1:postag=' + postag1,\n",
    "            '-1:postag[:2]=' + postag1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][2]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "            '+1:word.istitle=%s' % word1.istitle(),\n",
    "            '+1:word.isupper=%s' % word1.isupper(),\n",
    "            '+1:postag=' + postag1,\n",
    "            '+1:postag[:2]=' + postag1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "                \n",
    "    return features\n",
    "\n",
    "def sent2featuresposGaz(sent, personGaz, postagger):\n",
    "    tagged = postagger.tag(sent2features(sent))\n",
    "    sentNew = [word_nelabel+(pos, ) for word_nelabel,pos in zip(sent, tagged)]\n",
    "    return [word2featuresposGaz(sentNew, i, personGaz) for i in range(len(sentNew))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pos_gaz = [sent2featuresposGaz(s, personGazetteer, postagger) for s in train_corpus]\n",
    "y_train_pos_gaz = [sent2labels(s) for s in train_corpus]\n",
    "\n",
    "X_test_pos_gaz = [sent2featuresposGaz(s, personGazetteer,postagger) for s in test_corpus]\n",
    "y_test_pos_gaz = [sent2labels(s) for s in test_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainerposgaz = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X_train_pos_gaz, y_train_pos_gaz):\n",
    "    trainerposgaz.append(xseq, yseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainerposgaz.set_params({\n",
    "    'c1': 1.0,   # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 150,  # stop earlier\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.4 s, sys: 7.66 ms, total: 11.5 s\n",
      "Wall time: 11.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainerposgaz.train('twitter-ner-pos-gaz.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x7f7658067760>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taggerposgaz = pycrfsuite.Tagger()\n",
    "taggerposgaz.open('twitter-ner-pos-gaz.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 478 ms, sys: 11.3 ms, total: 489 ms\n",
      "Wall time: 488 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred_pos_gaz = [taggerposgaz.tag(xseq) for xseq in X_test_pos_gaz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with codecs.open('crf.out.pos.gaz.txt', 'w') as out_file:\n",
    "    for every_sent,pred_label in zip(test_corpus, y_pred_gaz):\n",
    "        for every_word_correct_label,predicted_label in zip(every_sent, pred_label):\n",
    "            out_file.write(every_word_correct_label[0] + \"\\t\" + every_word_correct_label[1] + \"\\t\" + predicted_label)\n",
    "            out_file.write(\"\\n\")\n",
    "        out_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_labels, predicted_labels = conllReader(\"crf.out.pos.gaz.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score is\n",
      "0.2762382718743181\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     company       0.75      0.10      0.18       586\n",
      "    facility       0.48      0.28      0.35       244\n",
      "     geo-loc       0.62      0.34      0.44       768\n",
      "       movie       0.14      0.04      0.06        28\n",
      " musicartist       0.12      0.01      0.01       180\n",
      "       other       0.27      0.08      0.12       535\n",
      "      person       0.34      0.41      0.38       466\n",
      "     product       0.29      0.02      0.04       216\n",
      "  sportsteam       0.00      0.00      0.00       128\n",
      "      tvshow       0.11      0.04      0.06        24\n",
      "\n",
      "   micro avg       0.45      0.20      0.28      3175\n",
      "   macro avg       0.31      0.13      0.16      3175\n",
      "weighted avg       0.45      0.20      0.25      3175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('F1 Score is')\n",
    "print( f1_score(true_labels, predicted_labels) )\n",
    "\n",
    "print('Classification report')\n",
    "print( classification_report(true_labels, predicted_labels, scheme=IOB1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This finishes the demonstration for the lab. Please go through the problem statement to complete your lab assignment.\n",
    "#### You are requested to submit it within the deadline for this assignment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "interpreter": {
   "hash": "7553fb56ab976ad5aff909b9ab0e5f0d2a23e397f8c044edf0a757925c0fad4d"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

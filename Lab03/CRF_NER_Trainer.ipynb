{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 03 - NLP - Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install python-crfsuite\n",
    "from itertools import chain\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import sklearn\n",
    "import pycrfsuite\n",
    "from nltk.corpus.reader import ConllChunkCorpusReader\n",
    "from seqeval.metrics import accuracy_score\n",
    "from seqeval.metrics import classification_report\n",
    "from seqeval.metrics import f1_score\n",
    "from seqeval.scheme import IOB1\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Train/Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycorpus = ConllChunkCorpusReader(r\"Twitter-NER/\", r\".*\\.train\",chunk_types=\"pos\")\n",
    "# mycorpus = ConllChunkCorpusReader(r\"../../MultiCoNER/test/HI-Hindi/\", r\"hi_train.conll\", chunk_types=\"pos\")\n",
    "\n",
    "train_corpus = []\n",
    "for tree in mycorpus.tagged_sents():\n",
    "    train_corpus.append(tree)\n",
    "    \n",
    "print(len(train_corpus))\n",
    "# print(train_corpus[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycorpus = ConllChunkCorpusReader(r\"Twitter-NER/\", r\".*\\.test\",chunk_types=\"pos\")\n",
    "# mycorpus = ConllChunkCorpusReader(r\"../../MultiCoNER/test/HI-Hindi/\", r\"hi_dev.conll\", chunk_types=\"pos\")\n",
    "\n",
    "test_corpus = []\n",
    "for tree in mycorpus.tagged_sents():\n",
    "    test_corpus.append(tree)\n",
    "print(len(test_corpus))\n",
    "# print(test_corpus[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features\n",
    "Next, define some features. In this example we use word identity, word suffix, word shape; also, some information from nearby words is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Every word is represented by a set of features. CRF allows us to give any arbitrary set of features\n",
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    features = [\n",
    "        'bias',\n",
    "        'word.lower=' + word.lower(),\n",
    "        'word[-3:]=' + word[-3:],\n",
    "        'word[-2:]=' + word[-2:],\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "    ]\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "            '-1:word.isupper=%s' % word1.isupper(),\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "            '+1:word.istitle=%s' % word1.istitle(),\n",
    "            '+1:word.isupper=%s' % word1.isupper(),\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "                \n",
    "    return features\n",
    "\n",
    "def word2featuresTest(sent, i):\n",
    "    word = sent[i]\n",
    "    features = [\n",
    "        'bias',\n",
    "        'word.lower=' + word.lower(),\n",
    "        'word[-3:]=' + word[-3:],\n",
    "        'word[-2:]=' + word[-2:],\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "    ]\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "            '-1:word.isupper=%s' % word1.isupper(),\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "            '+1:word.istitle=%s' % word1.istitle(),\n",
    "            '+1:word.isupper=%s' % word1.isupper(),\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "                \n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2featuresTest(sent):\n",
    "    return [word2featuresTest(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [sent2features(s) for s in train_corpus]\n",
    "y_train = [sent2labels(s) for s in train_corpus]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_corpus]\n",
    "y_test = [sent2labels(s) for s in test_corpus]\n",
    "\n",
    "print(train_corpus[5][0])\n",
    "print(X_train[5][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1%%time\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X_train, y_train):\n",
    "    trainer.append(xseq, yseq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.set_params({\n",
    "    'c1': 1.0,   # coefficient for L1 penalty\n",
    "    'c2': 1e-4,  # coefficient for L2 penalty\n",
    "    'max_iterations': 100,  # stop earlier\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trainer.train('twitter-ner.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('twitter-ner.crfsuite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_pred = [tagger.tag(xseq) for xseq in X_test]\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dumping Predictions to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open('crf.out.txt', 'w') as out_file:\n",
    "    for every_sent,pred_label in zip(test_corpus, y_pred):\n",
    "        for every_word_correct_label,predicted_label in zip(every_sent, pred_label):\n",
    "            out_file.write(every_word_correct_label[0] + \"\\t\" + every_word_correct_label[1] + \"\\t\" + predicted_label)\n",
    "            out_file.write(\"\\n\")\n",
    "        out_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conllReader(filename, word_field=0, label_field=1, prediction_field=2):\n",
    "    sentences_true_labels = []\n",
    "    sentences_pred_labels = []\n",
    "    true_list = []\n",
    "    pred_list = []\n",
    "    label_list = []\n",
    "    \n",
    "    with codecs.open(filename, 'r', errors='ignore', encoding='utf8') as f_in:\n",
    "        for line in f_in:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                if line.startswith('#'):\n",
    "                    continue\n",
    "                label = line.split('\\t')[label_field]\n",
    "                pred = line.split('\\t')[prediction_field]\n",
    "                true_list.append( label )\n",
    "                pred_list.append( pred )\n",
    "                \n",
    "            else:\n",
    "                if len(true_list) > 0:\n",
    "                    sentences_true_labels.append( true_list )\n",
    "                    sentences_pred_labels.append( pred_list )\n",
    "                true_list = []\n",
    "                pred_list = []\n",
    "        f_in.close()\n",
    "        \n",
    "    return sentences_true_labels, sentences_pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels, predicted_labels = conllReader(\"crf.out.txt\")\n",
    "# predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1 Score is')\n",
    "print( f1_score(true_labels, predicted_labels) )\n",
    "\n",
    "print('Classification report')\n",
    "print( classification_report(true_labels, predicted_labels, scheme=IOB1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attaching PoS Tagger-based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postagger = pycrfsuite.Tagger()\n",
    "postagger.open('twitter-ner.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Every word is represented by a set of features. CRF allows us to give any arbitrary set of features\n",
    "def word2featurespos(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][2]\n",
    "    features = [\n",
    "        'bias',\n",
    "        'word.lower=' + word.lower(),\n",
    "        'word[-3:]=' + word[-3:],\n",
    "        'word[-2:]=' + word[-2:],\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "        'postag=' + postag,\n",
    "        'postag[:2]=' + postag[:2],\n",
    "    ]\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][2]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "            '-1:word.isupper=%s' % word1.isupper(),\n",
    "            '-1:postag=' + postag1,\n",
    "            '-1:postag[:2]=' + postag1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][2]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "            '+1:word.istitle=%s' % word1.istitle(),\n",
    "            '+1:word.isupper=%s' % word1.isupper(),\n",
    "            '+1:postag=' + postag1,\n",
    "            '+1:postag[:2]=' + postag1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "                \n",
    "    return features\n",
    "\n",
    "def sent2featurespos(sent, postagger):\n",
    "    tagged = postagger.tag(sent2features(sent))\n",
    "    sentNew = [word_nelabel+(pos, ) for word_nelabel,pos in zip(sent, tagged)]\n",
    "    return [word2featurespos(sentNew, i) for i in range(len(sentNew))]\n",
    "\n",
    "def sent2labelspos(sent):\n",
    "    return [label for token, label in sent]\n",
    "\n",
    "def sent2tokenspos(sent):\n",
    "    return [token for token, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in train_corpus:\n",
    "    print(sent)\n",
    "    print(\"\\n\")\n",
    "    s1 = postagger.tag(sent2features(sent))\n",
    "    sentNew = [word_nelabel+(pos, ) for word_nelabel,pos in zip(sent, s1)]\n",
    "    print(sentNew)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pos = [sent2featurespos(s, postagger) for s in train_corpus]\n",
    "y_train_pos = [sent2labelspos(s) for s in train_corpus]\n",
    "\n",
    "X_test_pos = [sent2featurespos(s, postagger) for s in test_corpus]\n",
    "y_test_pos = [sent2labelspos(s) for s in test_corpus]\n",
    "\n",
    "# print(X_train_pos[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainerpos = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X_train_pos, y_train_pos):\n",
    "    trainerpos.append(xseq, yseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainerpos.set_params({\n",
    "    'c1': 1.0,   # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 100,  # stop earlier\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trainerpos.train('twitter-ner-pos.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taggerpos = pycrfsuite.Tagger()\n",
    "taggerpos.open('twitter-ner-pos.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_pred_pos = [taggerpos.tag(xseq) for xseq in X_test_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with codecs.open('crf.out.pos.txt', 'w') as out_file:\n",
    "    for every_sent,pred_label in zip(test_corpus, y_pred_pos):\n",
    "        for every_word_correct_label,predicted_label in zip(every_sent, pred_label):\n",
    "            out_file.write(every_word_correct_label[0] + \"\\t\" + every_word_correct_label[1] + \"\\t\" + predicted_label)\n",
    "            out_file.write(\"\\n\")\n",
    "        out_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels, predicted_labels = conllReader(\"crf.out.pos.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1 Score is')\n",
    "print( f1_score(true_labels, predicted_labels) )\n",
    "\n",
    "print('Classification report')\n",
    "print( classification_report(true_labels, predicted_labels, scheme=IOB1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Gazatteer features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus.reader import plaintext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personGazetteer = []\n",
    "\n",
    "mycorpus = plaintext.PlaintextCorpusReader(\"./Twitter-NER/\", \"firstname.5000\")\n",
    "person = []\n",
    "for sent in mycorpus.words():\n",
    "    person.append(sent)\n",
    "    \n",
    "mycorpus = plaintext.PlaintextCorpusReader(\"./Twitter-NER/\", \"lastname.5000\")\n",
    "for sent in mycorpus.words():\n",
    "    person.append(sent)\n",
    "\n",
    "person = [name.lower() for name in person]\n",
    "personGazetteer = set(person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Every word is represented by a set of features. CRF allows us to give any arbitrary set of features\n",
    "def word2featuresGaz(sent, i, personGaz):\n",
    "    word = sent[i][0]\n",
    "    features = [\n",
    "        'bias',\n",
    "        'word.lower=' + word.lower(),\n",
    "        'word[-3:]=' + word[-3:],\n",
    "        'word[-2:]=' + word[-2:],\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "        'word.ispersongaz=%s' % (word.lower() in personGaz),\n",
    "    ]\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "            '-1:word.isupper=%s' % word1.isupper(),\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "            '+1:word.istitle=%s' % word1.istitle(),\n",
    "            '+1:word.isupper=%s' % word1.isupper(),\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "                \n",
    "    return features\n",
    "\n",
    "def word2featuresTest(sent, i):\n",
    "    word = sent[i]\n",
    "    features = [\n",
    "        'bias',\n",
    "        'word.lower=' + word.lower(),\n",
    "        'word[-3:]=' + word[-3:],\n",
    "        'word[-2:]=' + word[-2:],\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "    ]\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "            '-1:word.isupper=%s' % word1.isupper(),\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "            '+1:word.istitle=%s' % word1.istitle(),\n",
    "            '+1:word.isupper=%s' % word1.isupper(),\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "                \n",
    "    return features\n",
    "\n",
    "def sent2featuresGaz(sent, personGaz):\n",
    "    return [word2featuresGaz(sent, i, personGaz) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_gaz = [sent2featuresGaz(s, personGazetteer) for s in train_corpus]\n",
    "y_train_gaz = [sent2labels(s) for s in train_corpus]\n",
    "\n",
    "X_test_gaz = [sent2featuresGaz(s, personGazetteer) for s in test_corpus]\n",
    "y_test_gaz = [sent2labels(s) for s in test_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainergaz = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X_train_gaz, y_train_gaz):\n",
    "    trainergaz.append(xseq, yseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainergaz.set_params({\n",
    "    'c1': 1.0,   # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 150,  # stop earlier\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trainergaz.train('twitter-ner-gaz.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taggergaz = pycrfsuite.Tagger()\n",
    "taggergaz.open('twitter-ner-gaz.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_pred_gaz = [taggergaz.tag(xseq) for xseq in X_test_gaz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with codecs.open('crf.out.gaz.txt', 'w') as out_file:\n",
    "    for every_sent,pred_label in zip(test_corpus, y_pred_gaz):\n",
    "        for every_word_correct_label,predicted_label in zip(every_sent, pred_label):\n",
    "            out_file.write(every_word_correct_label[0] + \"\\t\" + every_word_correct_label[1] + \"\\t\" + predicted_label)\n",
    "            out_file.write(\"\\n\")\n",
    "        out_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels, predicted_labels = conllReader(\"crf.out.gaz.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1 Score is')\n",
    "print( f1_score(true_labels, predicted_labels) )\n",
    "\n",
    "print('Classification report')\n",
    "print( classification_report(true_labels, predicted_labels, scheme=IOB1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding PoS Tag feature with the Gazetteer Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Every word is represented by a set of features. CRF allows us to give any arbitrary set of features\n",
    "def word2featuresposGaz(sent, i, personGaz):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][2]\n",
    "    features = [\n",
    "        'bias',\n",
    "        'word.lower=' + word.lower(),\n",
    "        'word[-3:]=' + word[-3:],\n",
    "        'word[-2:]=' + word[-2:],\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "        'postag=' + postag,\n",
    "        'postag[:2]=' + postag[:2],\n",
    "        'word.ispersongaz=%s' % (word.lower() in personGaz),\n",
    "    ]\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][2]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "            '-1:word.isupper=%s' % word1.isupper(),\n",
    "            '-1:postag=' + postag1,\n",
    "            '-1:postag[:2]=' + postag1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][2]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "            '+1:word.istitle=%s' % word1.istitle(),\n",
    "            '+1:word.isupper=%s' % word1.isupper(),\n",
    "            '+1:postag=' + postag1,\n",
    "            '+1:postag[:2]=' + postag1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "                \n",
    "    return features\n",
    "\n",
    "def sent2featuresposGaz(sent, personGaz, postagger):\n",
    "    tagged = postagger.tag(sent2features(sent))\n",
    "    sentNew = [word_nelabel+(pos, ) for word_nelabel,pos in zip(sent, tagged)]\n",
    "    return [word2featuresposGaz(sentNew, i, personGaz) for i in range(len(sentNew))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pos_gaz = [sent2featuresposGaz(s, personGazetteer, postagger) for s in train_corpus]\n",
    "y_train_pos_gaz = [sent2labels(s) for s in train_corpus]\n",
    "\n",
    "X_test_pos_gaz = [sent2featuresposGaz(s, personGazetteer,postagger) for s in test_corpus]\n",
    "y_test_pos_gaz = [sent2labels(s) for s in test_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainerposgaz = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X_train_pos_gaz, y_train_pos_gaz):\n",
    "    trainerposgaz.append(xseq, yseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainerposgaz.set_params({\n",
    "    'c1': 1.0,   # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 150,  # stop earlier\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "trainerposgaz.train('twitter-ner-pos-gaz.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taggerposgaz = pycrfsuite.Tagger()\n",
    "taggerposgaz.open('twitter-ner-pos-gaz.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "y_pred_pos_gaz = [taggerposgaz.tag(xseq) for xseq in X_test_pos_gaz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with codecs.open('crf.out.pos.gaz.txt', 'w') as out_file:\n",
    "    for every_sent,pred_label in zip(test_corpus, y_pred_pos_gaz):\n",
    "        for every_word_correct_label,predicted_label in zip(every_sent, pred_label):\n",
    "            out_file.write(every_word_correct_label[0] + \"\\t\" + every_word_correct_label[1] + \"\\t\" + predicted_label)\n",
    "            out_file.write(\"\\n\")\n",
    "        out_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_labels, predicted_labels = conllReader(\"crf.out.pos.gaz.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1 Score is')\n",
    "print( f1_score(true_labels, predicted_labels) )\n",
    "\n",
    "print('Classification report')\n",
    "print( classification_report(true_labels, predicted_labels, scheme=IOB1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This finishes the demonstration for the lab. Please go through the problem statement to complete your lab assignment.\n",
    "#### You are requested to submit it within the deadline for this assignment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "interpreter": {
   "hash": "7553fb56ab976ad5aff909b9ab0e5f0d2a23e397f8c044edf0a757925c0fad4d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69113ede-8dc5-4697-a00a-3aa73b4d9406",
   "metadata": {},
   "source": [
    "## In this assignment, we will implement a simple rule-based POS tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0713cef4-1d79-4bcc-bba7-8d1ed9fb87b3",
   "metadata": {},
   "source": [
    "First let's download the universal dependency treebank from the following url https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-4611"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b7b7f1-cb8e-4f76-b9b6-0ee4e1aeba1c",
   "metadata": {},
   "source": [
    "Create a folder named `data`. Copy the downloaded `ud-treebanks-v2.9.tgz` file into the current directory and untar it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfc9da3-8a8c-48b3-804a-4988718b9b8e",
   "metadata": {},
   "source": [
    "let us import some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed64767-36ac-43a3-9243-6cab1729507f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09c388d-65b1-4419-baf8-2ff201ede030",
   "metadata": {},
   "source": [
    "Now let's write some utility functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2a471e-9d28-4a0c-a038-c083876931de",
   "metadata": {},
   "source": [
    "### Utility Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86534632-7a71-430d-9354-3f6bad646068",
   "metadata": {},
   "source": [
    "#### Code to read data from CoNLL format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eb2c99-8868-4c4f-b3fb-4335437ca71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conllReader(filename, word_field=1, label_field=3):\n",
    "    sentences = []\n",
    "    sentence = []\n",
    "    label_list = []\n",
    "    \n",
    "    with codecs.open(filename, 'r', errors='ignore', encoding='utf8') as f_in:\n",
    "        for line in f_in:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                if line.startswith('# '):\n",
    "                    continue\n",
    "                    \n",
    "                word = line.split('\\t')[word_field]\n",
    "                label = line.split('\\t')[label_field]\n",
    "                \n",
    "                tokens = [word, label]\n",
    "                sentence.append( tokens )\n",
    "                \n",
    "                if label not in label_list:\n",
    "                    label_list.append( label )\n",
    "            else:\n",
    "                if len(sentence) > 0:\n",
    "                    sentences.append( sentence )\n",
    "                sentence = []\n",
    "        f_in.close()\n",
    "        \n",
    "    return sentences, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd96ca9-577d-4e28-8c45-90a9bdf3c7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split, label_list = conllReader('data/ud-treebanks-v2.9/UD_Tamil-TTB/ta_ttb-ud-train.conllu', word_field=1, label_field=3)\n",
    "\n",
    "print('Read {0} number of train sentences'.format( len(train_split) ))\n",
    "print('\\nFirst sentence looks like')\n",
    "print(train_split[0])\n",
    "\n",
    "print('\\n Labels used are')\n",
    "print(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275472da-ea56-4d4a-bbdf-a971c01a9e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMax(dictionary):    \n",
    "    max_key = list(dictionary.keys())[0]\n",
    "    max_value = dictionary[max_key]\n",
    "    for key in dictionary:\n",
    "        if max_value > dictionary[key]:\n",
    "            max_value = dictionary[key]\n",
    "            max_key = key\n",
    "            \n",
    "    return key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d591b14-1edf-46a7-82a5-b6d6974fc54a",
   "metadata": {},
   "source": [
    "Now we have the data loading part written, let's write a simple Most-Frequent POS tagger "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c802aa-fb41-4e16-9704-bf30ddf9b134",
   "metadata": {},
   "source": [
    "### Most Frequent POS Tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ff8640-6dfb-4ae5-bacc-0d5f7d0ac9a8",
   "metadata": {},
   "source": [
    "Let's load the train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72e2b51-de51-4b50-adcc-4c8050dbb928",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split, label_list = conllReader('data/ud-treebanks-v2.9/UD_Tamil-TTB/ta_ttb-ud-train.conllu', word_field=1, label_field=3)\n",
    "test_split, test_label_list = conllReader('data/ud-treebanks-v2.9/UD_Tamil-TTB/ta_ttb-ud-test.conllu', word_field=1, label_field=3)\n",
    "\n",
    "print('Read {0} number of train sentences'.format( len(train_split) ))\n",
    "print('Label list in train split is')\n",
    "print(label_list)\n",
    "\n",
    "print('\\n' * 2)\n",
    "print('Read {0} number of test sentences'.format( len(test_split) ))\n",
    "print('Label list in test split is')\n",
    "print(test_label_list)\n",
    "\n",
    "combined_label_list = list( set( label_list + test_label_list ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2ef401-2e5a-43d6-a5d5-d0aece309683",
   "metadata": {},
   "source": [
    "For every word in train split, let's get the POS statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a537634-6dbd-411e-bb8c-ecfb46742df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_pos_frequency = {}\n",
    "\n",
    "for every_sentence in train_split:\n",
    "    for every_token in every_sentence:\n",
    "        word, label = every_token\n",
    "        if word in word_pos_frequency:\n",
    "            if label in word_pos_frequency[word]:\n",
    "                word_pos_frequency[word][label] += 1\n",
    "            else:\n",
    "                word_pos_frequency[word][label] = 1\n",
    "        else:\n",
    "            word_pos_frequency[word] = {}\n",
    "            word_pos_frequency[word][label] = 1\n",
    "            \n",
    "print('Total number of words in train split is {0}'.format( len(word_pos_frequency) ) )\n",
    "first_word = next(iter(word_pos_frequency))\n",
    "print( 'Word is {0}'.format(first_word) )\n",
    "print( word_pos_frequency[first_word] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef6367b-55d8-481e-b85b-34bce239db9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 1\n",
    "for every_word in word_pos_frequency:\n",
    "    if len( word_pos_frequency[every_word] ) > 1:\n",
    "        if count == 1:\n",
    "            count += 1\n",
    "            continue\n",
    "        print( 'Word is {0}'.format(every_word) )\n",
    "        print( word_pos_frequency[every_word] )\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2de991-11f5-4b49-b8ec-4da572bd8dac",
   "metadata": {},
   "source": [
    "### Evaluate on test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d18dba-bb24-4598-84c6-1306dbe74846",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = []\n",
    "prediction = []\n",
    "\n",
    "total_num_tokens = 0\n",
    "tokens_present_in_train = 0\n",
    "\n",
    "for every_sentence in test_split:\n",
    "    ground_truth_sentence = []\n",
    "    prediction_sentence = []\n",
    "\n",
    "    for every_token in every_sentence:\n",
    "        word, label = every_token\n",
    "        ground_truth_sentence.append( label )\n",
    "        \n",
    "        total_num_tokens += 1\n",
    "\n",
    "        if word in word_pos_frequency:\n",
    "            tokens_present_in_train += 1\n",
    "            prediction_sentence.append( getMax( word_pos_frequency[word] ) )\n",
    "        else:\n",
    "            prediction_sentence.append( random.choice( label_list ) )\n",
    "            \n",
    "    ground_truth.append( ground_truth_sentence )\n",
    "    prediction.append( prediction_sentence )\n",
    "    \n",
    "print(\"Out of {0} number of words in test split, {1} appeared in train split\".format( total_num_tokens, tokens_present_in_train ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a29f089-5e3e-441d-9c7f-18e2d81915f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_gold_truth = [j for sub in ground_truth for j in sub]\n",
    "flatten_predictions = [j for sub in prediction for j in sub]\n",
    "\n",
    "print(classification_report(flatten_gold_truth, flatten_predictions, target_names=combined_label_list, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ab234a-1a33-4a1e-ac53-5415e8e35b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(flatten_gold_truth, flatten_predictions)\n",
    "\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=combined_label_list)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_figheight(15)\n",
    "fig.set_figwidth(15)\n",
    "\n",
    "cmd.plot(xticks_rotation='vertical', ax =ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2faa4d3-1e0a-4241-a914-c91ff68febd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# For tasks requiring phrase-level annotation\n",
    "# from seqeval.metrics import accuracy_score\n",
    "# from seqeval.metrics import classification_report\n",
    "# from seqeval.metrics import f1_score\n",
    "# from seqeval.scheme import IOB1\n",
    "# print('F1 Score is')\n",
    "# print( f1_score(ground_truth, prediction) )\n",
    "\n",
    "# print('Classification report')\n",
    "# print( classification_report(ground_truth, prediction, scheme=IOB1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab677fa-bbe9-4355-92b0-7aedd4fce9b3",
   "metadata": {},
   "source": [
    "## Implement Rule-based System here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9450e7-6f6c-4dd2-9c5b-86bcd67c1f98",
   "metadata": {},
   "source": [
    "Let us write a simple rule to tag adverbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b21043f-b5a3-4c42-90af-bc3aa2aba3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "affix_pos_frequency = {}\n",
    "\n",
    "for every_word in word_pos_frequency:\n",
    "    bi_gram_character = every_word[ -2: ]\n",
    "    tri_gram_character = every_word[ -3: ]\n",
    "\n",
    "    if bi_gram_character in affix_pos_frequency:\n",
    "        for key in word_pos_frequency[ every_word ]:\n",
    "            if key in affix_pos_frequency[bi_gram_character]:\n",
    "                affix_pos_frequency[bi_gram_character][key] += word_pos_frequency[ every_word ][key]\n",
    "            else:\n",
    "                affix_pos_frequency[bi_gram_character][key] = word_pos_frequency[ every_word ][key]\n",
    "    else:\n",
    "        affix_pos_frequency[bi_gram_character] = word_pos_frequency[every_word]\n",
    "\n",
    "    if tri_gram_character in affix_pos_frequency:\n",
    "        for key in word_pos_frequency[ every_word ]:\n",
    "            if key in affix_pos_frequency[tri_gram_character]:\n",
    "                affix_pos_frequency[tri_gram_character][key] += word_pos_frequency[ every_word ][key]\n",
    "            else:\n",
    "                affix_pos_frequency[tri_gram_character][key] = word_pos_frequency[ every_word ][key]\n",
    "    else:\n",
    "        affix_pos_frequency[tri_gram_character] = word_pos_frequency[every_word]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad119c5-4b6d-4a43-9a2e-a5698e55f393",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = []\n",
    "prediction = []\n",
    "\n",
    "for every_sentence in test_split:\n",
    "    ground_truth_sentence = []\n",
    "    prediction_sentence = []\n",
    "\n",
    "    word_index = 0\n",
    "    for every_token in every_sentence:\n",
    "        word_index = word_index + 1\n",
    "        word, label = every_token\n",
    "        ground_truth_sentence.append( label )\n",
    "        \n",
    "        word_bi_gram = every_token[0][-2:]\n",
    "        word_tri_gram = every_token[0][-3:]\n",
    "        \n",
    "        if word in word_pos_frequency:\n",
    "            prediction_sentence.append( getMax( word_pos_frequency[word] ) )\n",
    "        elif word_tri_gram in affix_pos_frequency:\n",
    "            prediction_sentence.append( getMax( affix_pos_frequency[word_tri_gram] ) )\n",
    "        elif word_bi_gram in affix_pos_frequency:\n",
    "            prediction_sentence.append( getMax( affix_pos_frequency[word_bi_gram] ) )\n",
    "        else:\n",
    "            prediction_sentence.append( random.choice( combined_label_list ) )\n",
    "\n",
    "    ground_truth.append( ground_truth_sentence )\n",
    "    prediction.append( prediction_sentence )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89249aa-45cd-420d-8222-08534fd5ff88",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_gold_truth = [j for sub in ground_truth for j in sub]\n",
    "flatten_predictions = [j for sub in prediction for j in sub]\n",
    "\n",
    "print(classification_report(flatten_gold_truth, flatten_predictions, target_names=combined_label_list, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde39200-4dc0-4ad6-8b57-feeba3e0c901",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlplab] *",
   "language": "python",
   "name": "conda-env-nlplab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
